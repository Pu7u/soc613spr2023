---
title: 'Week 6: Cohesion and Community'
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float: yes
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

How do social actors or entities connect to one another? On its face the answer is obvious: Actors are directly tied to one another through social relations (friends with, talks to, advice from, and so on). But, social scientists for some time have viewed social connectivity more broadly to include how actors connect to one another through indirect ties through co-membership or affiliation (members of the same team, members of the same corporate board, co-authorhip, and so on). As Cooley wrote,  “A man may regarded as the point of intersection of an indefinite number of circles representing social groups, having as many arcs passing through him as there are groups.” 

When we discussion affiliation networks, we ask:

What does it mean to be affiliated through a literal group, activity, or event?
 
And we may also ask: 
 
What does it mean to be connected through a generic group or an abstraction?

It is probably not controversial to claim that people who are in the exact same social group share some type of meaningful connection through being members in the same group. If I attend a book club with you, then I am likely to share numerous characteristics, at minimum a shared appreciation of similar books. However, if we attend book clubs in different cities, does generic book club membership provide a meaningful tie?

Scholars interested in duality and affiliation are interested in these kinds of questions, but they extend to non-human entities as well, like scientific papers or emotions, that can be modeled as two-mode or affiliation networks.

Earlier work on duality (Breiger 1974) builds upon Cooley's idea: People intersect through their associations, which defines (in part) their individuality. The concept of duality recognizes that relations among groups implies relations among individuals or vice versa. 

As Breiger(1974:87) writes, "With respect to the membership network...persons who are actors in one picture (the P matrix) are with equal legitimacy viewed as connections in the dual picture (the G matrix), and conversely for groups."

The resulting network after these transformations:
    - Is always symmetric
    - The diagonal tells you how many groups (persons) a person (group) belongs to (has).

We can see how these types of transformations work by turning to a toy example.

First, we should load the packages that we will need in this workshop. We will use **igraph** for network analysis and visualization, **ggraph** for visualization, **udpipe** for some language parsing, and **dplyr**, **tidygraph**, and **ggforce** for a few data organization and visualization tasks.

```{r, message=FALSE}
library(igraph)
library(ggraph)
library(udpipe)
library(dplyr)
library(tidygraph)
library(ggforce)
```

## Affiliation Example

Let's begin with a person-to-group matrix
 
Each column is a group, each cell is a person, and the cell=1 if the person in that row belongs to the group in that column. You can calculate how many groups shared between two individuals by comparing the rows. Identify every column where both rows equals 1 and sum them. This is the overlap.
![](images/example_matrix.JPG)

You can also tell the total number of group members by summing the columns and the total number of groups/indvidual by summing the rows.

Let's make a matrix in **R**.

```{r, echo=T}
one <- c(0, 1, 1, 0, 0, 0)
two <- c(0, 0, 1, 1, 0, 0)
three <- c(0, 0, 0, 1, 1, 1)
four <- c(0, 0, 0, 1, 0, 1)
five <- c(1, 0, 0, 1, 0, 0)

dual <- cbind(one, two, three, four, five)

rownames(dual) <- c("A", "B", "C", "D", "E", "F")

print(dual)

```

## Duality, Transformations, Matrix Algebra

Recall that the matrix is a simple and elegant way to manipulate networks. That is most obviously the case, perhaps, when thinking through duality.

From persons-to-groups to persons *and* groups.

If we multiple our Persons-to-Group matrix by its transpose, we have a Person matrix.

If we multiply the transpose of our Persons-to-Group matrix by the matrix itself, we have the Groups matrix.

![](images/matrix_operations.JPG)

The Person-Person Matrix:

```{r, echo=T}

person <- dual %*% t(dual)

print(person)

```

The Group-Group Matrix:

```{r, echo=T}

groups <- t(dual) %*% dual

print(groups)

```

## Bipartite Network

The general class of affiliation networks are known as *bipartite* or *two-mode* networks. The matrix transformation described above where we transform the network from two-mode to one-mode is called a *projection*.

One-mode projections, while perhaps more easy to understand, obviously involve a substantial loss of information. 

While it remains more common, perhaps, to project two-mode networks, increasing work is looking at the tractability of keeping two-mode networks as two-modes.

## Text Networks

Text networks are increasingly common and relatively simple methods for document classification and/or generating thematic relationships across texts.

The goal is data reduction: Take a bunch of texts and simplify the relationship between them and/or their ideas.

Fundamentally, these are bipartite networks consisting of documents and words. We can think of any number of networks in similar ways, such as cocitation networks that consist of documents and citations. 

Steps in processing texts:

    1. Find a collection of texts
    2. Force the collection into a .csv (etc.)
    3. Preprocess the text data
        - Remove stop words and or select POS (e.g. nouns)
        - N-grams?
        - Word length
        - Common words
    4. Build document by word matrix
        - "Bag of words:" Word order doesn't matter
        - Weighted elements?: Common weight is tfidf
    5. Project to terms or documents
    6. Plot

Let's build a text network and a network of documents from the Web of Science on "computational social science."

## Download Data

I will be providing an overview of downloading data in Web of Science. We download these data manually at this point and use the **bibliometrix** package to bring the data into a useable file and export to a .csv.

So, we can also start by reading the data in .csv form:

```{r, echo=T, message=FALSE}
comp <- read.csv("data/comp_socsci.csv")
```

## Organize and Clean Data

We can organize and clean the data by deleting articles that don't have an abstract and by combining keywords, titles, and abstracts. 

Next, we can parse the combined text field and tag the words in the field by part-of-speech by using a pos-tagger. In this case, we use **udpipe** by first downloading an English language model using ``udpipe_download_model(language = "english-lines")`` then loading it into our **R** session with the local path using ``udpipe_load_model(file=pathname)``. Last, we use ``udpipe_annotate`` on the text field to tag each word with a part of speech. Here, we also use ``filter`` in **dplyr** to select on nouns, but you may or may not want to look only at nouns.

```{r, echo=T, message=FALSE}

comp <- comp %>% filter(AB != "")

comp$text <- paste(comp$DE, comp$TI, comp$AB)

m_eng_lines   <- udpipe_download_model(language = "english-lines")
m_eng_lines_path <- m_eng_lines$file_model
m_eng_lines_loaded <- udpipe_load_model(file=m_eng_lines_path)

text_annotated <- udpipe_annotate(m_eng_lines_loaded, x = comp$text) %>%
      as.data.frame() %>%
      select(-sentence)

nouns <- text_annotated %>% filter(upos=="NOUN")

```

After we select nouns, we can also clean the data in some ways that are typical for text networks, such as getting rid of short words, numbers, and words that appear only a handful of times, here 10 or fewer times. You see that most of these cleaning steps use either **base R** or **dplyr**.

```{r, echo=T, message=FALSE}

nouns$lemma <- tolower(nouns$lemma)

word_count <-as.data.frame(table(nouns$lemma))

word_count <- rename(word_count, lemma = Var1)

word_count$isnum <- nchar(gsub("[^0-9]+", "", word_count$lemma))

word_count <- word_count %>% filter(isnum==0)

word_count$lemma <- as.character(word_count$lemma)

word_count$wlength <- nchar(word_count$lemma)

word_count <- word_count %>% filter(wlength>3)

word_count <- word_count %>% filter(Freq>10)

word_count$keep <- 1

noun_fin <- left_join(nouns, word_count)

noun_fin[is.na(noun_fin)] = 0

noun_fin <- noun_fin %>% filter(keep==1)

```

## Computational Social Science Text Network

The output of the data cleaning process results in a edge list, if we ``select`` (from **dplyr**) on the lemma - or root word - and the doc_id. Next, we can use ``graph_from_data_frame`` on this data frame edge list to create an **igraph** network. The ``bipartite.mapping`` function in **igraph** identifies both of the modes and we store it as a node attribute in the usual way (``V(g)$attribute``). To project this two mode network into a one mode network, we can use the ``bipartite_projection`` function, where "multiplicity" indicates whether the co-appearances should be added together as an edge weight and where "which" is FALSE is the first mode and TRUE is the second mode. As the the lemma is in the first column, we can choose FALSE here.


```{r, echo=T, message=FALSE}

noun_edge <- noun_fin %>% select(lemma, doc_id)

noun.g <- graph_from_data_frame(noun_edge)

V(noun.g)$type <- bipartite.mapping(noun.g)$type

n1mode.g <- bipartite_projection(noun.g, multiplicity = TRUE, which=FALSE)

V(n1mode.g)$wrd_cnt <- word_count$Freq

n1mode.g <- delete.vertices(n1mode.g, V(n1mode.g)[ degree(n1mode.g)==0]) 

plot(n1mode.g, layout=layout_with_kk, vertex.size=V(n1mode.g)$wrd_cnt/10, main="Computational Social Science Noun Network")

```

This is a messy graph, so we can use **ggraph** to clean it up and engage some other editing like using ``delete.edges`` in **igraph** where we use ``quantile`` function to grab the top 10 percent of edges. 

```{r, echo=TRUE, message=FALSE}


n1sub.g <- delete.edges(n1mode.g, which(E(n1mode.g)$weight < (quantile(E(n1mode.g)$weight, .90)
)))

n1sub.g <- delete.vertices(n1sub.g, V(n1sub.g)[ degree(n1sub.g)==0 ]) 

cls_fast <- cluster_fast_greedy(n1sub.g)

membs <- data.frame(clusters=as.numeric(cls_fast$membership))

clrs <- data.frame(clusters=c(1,2,3,4,5), clr=c("purple", "yellow", "green", "skyblue", "red"))

membs <- left_join(membs, clrs)

ggraph(n1sub.g, layout = "kk") + 
  geom_edge_link(alpha=.25, aes(width=weight), color="gray") + 
  geom_node_point(aes(size=wrd_cnt, fill = membs$clr), shape=21) +
  geom_node_text(aes(label=ifelse(wrd_cnt > 100, name, NA))) +
  scale_size_continuous(range = c(2, 20))   +
  theme_void() +
  theme(legend.position = "none") +
  labs(title="Computational Social Science Text Network", caption = "This graph visualizes the text network for computational social science based on words in the abstract, title, and keywords.
  Nodes are words. Edges are the count of overlaps across articles. Communities using FastGreedy. 
  Node labels are words that appear in at least 100 articles.")
```
